"""
AI-Powered Vulnerability Analysis System
Deep learning-based vulnerability detection and exploit generation
"""

import asyncio
import os
from typing import Dict, List, Optional
import logging
from openai import OpenAI

log = logging.getLogger(__name__)


class AIVulnerabilityAnalyzer:
    """
    AI-Powered Vulnerability Analysis
    
    Features:
    - Deep learning vulnerability detection
    - Pattern recognition for zero-day discovery
    - Automated exploit generation
    - Success rate prediction
    - Attack path optimization
    """
    
    def __init__(self):
        self.client = OpenAI()  # API key from environment
        self.model = os.getenv('OPENAI_MODEL', 'gpt-4.1-mini')
        self.vulnerability_patterns = []
        self.exploit_templates = []
    
    async def run(self, target: Dict) -> Dict:
        """
        Main entry point for AI vulnerability analysis
        
        Args:
            target: Dict containing:
                - url: Target URL
                - source_code: Source code to analyze (optional)
                - binary_path: Binary to analyze (optional)
                - scan_results: Previous scan results (optional)
        
        Returns:
            Dict with vulnerability analysis
        """
        url = target.get('url')
        source_code = target.get('source_code')
        binary_path = target.get('binary_path')
        scan_results = target.get('scan_results', {})
        
        try:
            # Analyze vulnerabilities
            vulnerabilities = await self.analyze_vulnerabilities(
                url=url,
                source_code=source_code,
                binary_path=binary_path,
                scan_results=scan_results
            )
            
            # Generate exploits
            exploits = await self.generate_exploits(vulnerabilities)
            
            # Predict success rates
            predictions = await self.predict_success_rates(exploits)
            
            return {
                'success': True,
                'vulnerabilities': vulnerabilities,
                'exploits': exploits,
                'predictions': predictions
            }
        
        except Exception as e:
            log.error(f"[AIVulnAnalyzer] Error: {e}")
            return {
                'success': False,
                'error': str(e)
            }
    
    async def analyze_vulnerabilities(
        self,
        url: Optional[str] = None,
        source_code: Optional[str] = None,
        binary_path: Optional[str] = None,
        scan_results: Dict = None
    ) -> List[Dict]:
        """
        Analyze target for vulnerabilities using AI
        
        Returns:
            List of detected vulnerabilities
        """
        log.info("[AIVulnAnalyzer] Analyzing vulnerabilities with AI")
        
        vulnerabilities = []
        
        # Prepare context for AI
        context = self._prepare_context(url, source_code, binary_path, scan_results)
        
        # AI analysis prompt
        prompt = f"""Analyze the following target for security vulnerabilities:

{context}

Identify all potential vulnerabilities including:
1. SQL Injection
2. Cross-Site Scripting (XSS)
3. Remote Code Execution (RCE)
4. Server-Side Request Forgery (SSRF)
5. Authentication Bypass
6. Buffer Overflow
7. Use-After-Free
8. Integer Overflow
9. Path Traversal
10. Insecure Deserialization

For each vulnerability found, provide:
- Type
- Severity (Critical/High/Medium/Low)
- Location (URL, function, line number)
- Description
- Exploitation difficulty
- Potential impact

Format as JSON array."""
        
        try:
            # Call AI model
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert security researcher specializing in vulnerability analysis and exploit development."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=2000
            )
            
            # Parse response
            ai_response = response.choices[0].message.content
            
            # Extract vulnerabilities from AI response
            vulnerabilities = self._parse_vulnerabilities(ai_response)
            
            log.info(f"[AIVulnAnalyzer] Found {len(vulnerabilities)} vulnerabilities")
            
        except Exception as e:
            log.error(f"[AIVulnAnalyzer] AI analysis failed: {e}")
        
        return vulnerabilities
    
    async def generate_exploits(self, vulnerabilities: List[Dict]) -> List[Dict]:
        """
        Generate exploits for detected vulnerabilities using AI
        
        Args:
            vulnerabilities: List of vulnerabilities
        
        Returns:
            List of generated exploits
        """
        log.info("[AIVulnAnalyzer] Generating exploits with AI")
        
        exploits = []
        
        for vuln in vulnerabilities:
            try:
                exploit = await self._generate_single_exploit(vuln)
                if exploit:
                    exploits.append(exploit)
            except Exception as e:
                log.error(f"[AIVulnAnalyzer] Exploit generation failed for {vuln.get('type')}: {e}")
        
        return exploits
    
    async def _generate_single_exploit(self, vulnerability: Dict) -> Optional[Dict]:
        """Generate exploit for a single vulnerability"""
        
        vuln_type = vulnerability.get('type')
        location = vulnerability.get('location')
        description = vulnerability.get('description')
        
        prompt = f"""Generate a working exploit for the following vulnerability:

Type: {vuln_type}
Location: {location}
Description: {description}

Provide:
1. Exploit code (Python or Bash)
2. Step-by-step exploitation process
3. Expected output
4. Mitigation recommendations

Format as JSON with fields: code, steps, expected_output, mitigation"""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert exploit developer. Generate working, ethical exploits for security testing."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.8,
                max_tokens=1500
            )
            
            ai_response = response.choices[0].message.content
            
            exploit = self._parse_exploit(ai_response, vulnerability)
            
            return exploit
        
        except Exception as e:
            log.error(f"[AIVulnAnalyzer] Exploit generation failed: {e}")
            return None
    
    async def predict_success_rates(self, exploits: List[Dict]) -> List[Dict]:
        """
        Predict success rates for exploits using ML
        
        Args:
            exploits: List of exploits
        
        Returns:
            List of predictions
        """
        log.info("[AIVulnAnalyzer] Predicting success rates")
        
        predictions = []
        
        for exploit in exploits:
            prediction = await self._predict_single_success_rate(exploit)
            predictions.append(prediction)
        
        return predictions
    
    async def _predict_single_success_rate(self, exploit: Dict) -> Dict:
        """Predict success rate for a single exploit"""
        
        # Factors affecting success rate
        factors = {
            'vulnerability_type': exploit.get('vulnerability_type'),
            'severity': exploit.get('severity'),
            'complexity': exploit.get('complexity', 'medium'),
            'target_type': exploit.get('target_type', 'web')
        }
        
        # Simple heuristic-based prediction
        # In production, use trained ML model
        
        base_rate = 0.5
        
        # Adjust based on severity
        severity_multiplier = {
            'critical': 1.3,
            'high': 1.1,
            'medium': 1.0,
            'low': 0.8
        }
        
        base_rate *= severity_multiplier.get(factors['severity'].lower(), 1.0)
        
        # Adjust based on complexity
        complexity_multiplier = {
            'easy': 1.2,
            'medium': 1.0,
            'hard': 0.7
        }
        
        base_rate *= complexity_multiplier.get(factors['complexity'].lower(), 1.0)
        
        # Cap at 0.95
        success_rate = min(base_rate, 0.95)
        
        return {
            'exploit_id': exploit.get('id'),
            'success_rate': success_rate,
            'confidence': 0.75,
            'factors': factors
        }
    
    async def optimize_attack_path(self, vulnerabilities: List[Dict]) -> List[Dict]:
        """
        Optimize attack path using AI
        
        Args:
            vulnerabilities: List of vulnerabilities
        
        Returns:
            Optimized attack sequence
        """
        log.info("[AIVulnAnalyzer] Optimizing attack path")
        
        prompt = f"""Given the following vulnerabilities, determine the optimal attack sequence:

{vulnerabilities}

Consider:
1. Exploitation difficulty
2. Success probability
3. Stealth requirements
4. Impact maximization
5. Lateral movement opportunities

Provide an ordered attack sequence with reasoning."""
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "You are an expert penetration tester specializing in attack path optimization."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=1000
            )
            
            ai_response = response.choices[0].message.content
            
            attack_path = self._parse_attack_path(ai_response)
            
            return attack_path
        
        except Exception as e:
            log.error(f"[AIVulnAnalyzer] Attack path optimization failed: {e}")
            return vulnerabilities  # Return original order
    
    def _prepare_context(
        self,
        url: Optional[str],
        source_code: Optional[str],
        binary_path: Optional[str],
        scan_results: Dict
    ) -> str:
        """Prepare context for AI analysis"""
        
        context_parts = []
        
        if url:
            context_parts.append(f"Target URL: {url}")
        
        if source_code:
            context_parts.append(f"Source Code:\\n{source_code[:2000]}")  # Limit size
        
        if binary_path:
            context_parts.append(f"Binary: {binary_path}")
        
        if scan_results:
            context_parts.append(f"Scan Results:\\n{scan_results}")
        
        return "\\n\\n".join(context_parts)
    
    def _parse_vulnerabilities(self, ai_response: str) -> List[Dict]:
        """Parse vulnerabilities from AI response"""
        
        # Simple parsing - in production, use more robust JSON parsing
        vulnerabilities = []
        
        try:
            import json
            import re
            
            # Extract JSON from response
            json_match = re.search(r'\\[.*\\]', ai_response, re.DOTALL)
            if json_match:
                vulns = json.loads(json_match.group(0))
                vulnerabilities = vulns
        except:
            # Fallback: parse as text
            pass
        
        return vulnerabilities
    
    def _parse_exploit(self, ai_response: str, vulnerability: Dict) -> Dict:
        """Parse exploit from AI response"""
        
        exploit = {
            'id': f"exploit_{vulnerability.get('type')}_{id(vulnerability)}",
            'vulnerability_type': vulnerability.get('type'),
            'severity': vulnerability.get('severity'),
            'code': ai_response,  # Full AI response as code
            'complexity': 'medium',
            'target_type': 'web'
        }
        
        return exploit
    
    def _parse_attack_path(self, ai_response: str) -> List[Dict]:
        """Parse attack path from AI response"""
        
        # Simple parsing - return as-is
        return [{'step': ai_response}]


if __name__ == '__main__':
    async def test():
        analyzer = AIVulnerabilityAnalyzer()
        
        result = await analyzer.run({
            'url': 'http://example.com',
            'scan_results': {
                'open_ports': [80, 443],
                'technologies': ['Apache', 'PHP']
            }
        })
        
        print(f"Analysis result: {result}")
    
    asyncio.run(test())

